---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 
We use (`*`) to indicate a problem that we think might be time consuming. 
    
## Style Points (10 pts) 
Please refer to the minilesson on code style
**[here](https://uchicago.zoom.us/rec/share/pG_wQ-pHTQrJTmqNn4rcrw5V194M2H2s-2jdy8oVhWHkd_yZt9o162IWurpA-fxU.BIQlSgZLRYctvzp-)**.

## Submission Steps (10 pts)
1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person *Partner 1*.
    - Partner 1 (name and cnet ID):
    - Partner 2 (name and cnet ID):
3. Partner 1 will accept the `ps4` and then share the link it creates with their partner. You can only share it with one partner so you will not be able to change it after your partner has accepted. 
4. "This submission is our work alone and complies with the 30538 integrity policy." Add your initials to indicate your agreement: \*\*\_\_\*\* \*\*\_\_\*\*
5. "I have uploaded the names of anyone else other than my partner and I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  (1 point)
6. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*
7. Knit your `ps4.qmd` to an PDF file to make `ps4.pdf`, 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
8. (Partner 1): push  `ps4.qmd` and `ps4.pdf` to your github repo.
9. (Partner 1): submit `ps4.pdf` via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**Important:** Repositories are for tracking code. **Do not commit the data or shapefiles to your repo.** The best way to do this is with `.gitignore`, which we have covered in class. If you do accidentally commit the data, Github has a [guide](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github#removing-files-from-a-repositorys-history). The best course of action depends on whether you have pushed yet. This also means that both partners will have to download the initial raw data and any data cleaning code will need to be re-run on both partners' computers. 

## Download and explore the Provider of Services (POS) file (10 pts)

1. The variables I pulled are PRVDR_CTGRY_SBTYP_CD, PRVDR_CTGRY_CD, PRVDR_NUM, PGM_TRMNTN_CD, FAC_NAME and ZIP_CD
2. Importing the dataset

```{python}
import pandas as pd
import altair as alt
```

```{python}
#hospitals_2016 = pd.read_csv("/Users/kishikamahajan/Desktop/pos2016.csv")
hospitals_2016 = pd.read_csv("/Users/nidhi/Desktop/Data and Programming Python 2/POS_File_Hospital_Non_Hospital_Facilities_Q4_2016.csv")
hospitals_2016.head()

# Subsetting the hospitals
short_term_hospitals_2016 = hospitals_2016[(hospitals_2016["PRVDR_CTGRY_CD"] == 1) & (hospitals_2016["PRVDR_CTGRY_SBTYP_CD"] == 1)]

# Adding a column for the year
short_term_hospitals_2016["YEAR"] = 2016

short_term_hospitals_2016.shape[0]
```

    a. The number of hospitals reported in this data are 7245. 
    b. # ADD ANSWER HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!

3. Importing the datasets
```{python}
# FOR 2017
#hospitals_2017 = pd.read_csv("/Users/kishikamahajan/Desktop/pos2017.csv")
hospitals_2017 = pd.read_csv("/Users/nidhi/Desktop/Data and Programming Python 2/POS_File_Hospital_Non_Hospital_Facilities_Q4_2017.csv")
hospitals_2017.head()

# Subsetting the hospitals
short_term_hospitals_2017 = hospitals_2017[(hospitals_2017["PRVDR_CTGRY_CD"] == 1) & (hospitals_2017["PRVDR_CTGRY_SBTYP_CD"] == 1)]

# Adding a column for the year
short_term_hospitals_2017["YEAR"] = 2017

print(f"The short term hospitals in 2017 were {short_term_hospitals_2017.shape[0]}")
```

# ADD ABOUT IF IT MAKES SENSE !!!!!!!!!!!!!!!!!!!!!!!!

```{python}
# FOR 2018
#hospitals_2018 = pd.read_csv("/Users/kishikamahajan/Desktop/pos2018.csv" , encoding="ISO-8859-1")
hospitals_2018 = pd.read_csv("/Users/nidhi/Desktop/Data and Programming Python 2/POS_File_Hospital_Non_Hospital_Facilities_Q4_2018.csv" , encoding="ISO-8859-1")
hospitals_2018.head()

# Subsetting the hospitals
short_term_hospitals_2018 = hospitals_2018[(hospitals_2018["PRVDR_CTGRY_CD"] == 1) & (hospitals_2018["PRVDR_CTGRY_SBTYP_CD"] == 1)]

# Adding a column for the year
short_term_hospitals_2018["YEAR"] = 2018

print(f"The short term hospitals in 2018 were {short_term_hospitals_2018.shape[0]}")
```

# ADD ABOUT IF IT MAKES SENSE !!!!!!!!!!!!!!!!!!!!!!!!

```{python}
# FOR 2019
#hospitals_2019 = pd.read_csv("/Users/kishikamahajan/Desktop/pos2019.csv" , encoding="ISO-8859-1")
hospitals_2019 = pd.read_csv("/Users/nidhi/Desktop/Data and Programming Python 2/POS_File_Hospital_Non_Hospital_Facilities_Q4_2019.csv" , encoding="ISO-8859-1")
hospitals_2019.head()

# Subsetting the hospitals
short_term_hospitals_2019 = hospitals_2019[(hospitals_2019["PRVDR_CTGRY_CD"] == 1) & (hospitals_2019["PRVDR_CTGRY_SBTYP_CD"] == 1)]

# Adding a column for the year
short_term_hospitals_2019["YEAR"] = 2019

print(f"The short term hospitals in 2019 were {short_term_hospitals_2019.shape[0]}")
```

# ADD ABOUT IF IT MAKES SENSE !!!!!!!!!!!!!!!!!!!!!!!!

Appending the datasets together
```{python}
combined_short_term_hospitals = pd.concat([short_term_hospitals_2016, short_term_hospitals_2017, short_term_hospitals_2018, short_term_hospitals_2019], ignore_index=True)
combined_short_term_hospitals.head()
```

Plotting the number of hospitals by year
```{python}
# grouping by year
hospitals_by_year = combined_short_term_hospitals.groupby("YEAR").size().reset_index(name = "number_of_hospitals")

# plotting the number of observations by year
alt.Chart(hospitals_by_year).mark_bar().encode(
    alt.X("YEAR:N" , title = "Year"),
    alt.Y("number_of_hospitals" , title = "Number of Hospitals")
)
```


4. Plotting the unique number of hospitals by year
```{python}
unique_hospitals_by_year = (
    combined_short_term_hospitals.groupby("YEAR")["PRVDR_NUM"].nunique().reset_index(name = "unique_hospitals")
)

# plotting the unique number of hospitals
alt.Chart(unique_hospitals_by_year).mark_bar().encode(
    alt.X("YEAR:N" , title = "Year"),
    alt.Y("unique_hospitals" , title = "Number of Unique Hospitals")
)
```

    a. # ADD ANSWER HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    b. # ADD ANSWER HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!

## Identify hospital closures in POS file (15 pts) (*)

1. 


```{python}
#Identifying unique column
unique_columns = [col for col in short_term_hospitals_2016.columns if short_term_hospitals_2016[col].is_unique]
print("Columns with all unique values:", unique_columns)
```


```{python}

termination_active_2016 = short_term_hospitals_2016[short_term_hospitals_2016['PGM_TRMNTN_CD']==0]
termination_active_2016

termination_active_2016_s = termination_active_2016[['PGM_TRMNTN_CD', 'FAC_NAME', 'ZIP_CD','YEAR','PRVDR_NUM']]


def terminated_hospitals(years, short_term_hospital_mapping):
    # Empty list to store results
    terminated_hospitals_list = []
    
    for year in years:
        short_term_hospital_year = short_term_hospital_mapping[year]
        
        # Creating a subset of data by selecting columns
        short_term_hospital_year_s = short_term_hospital_year[['PGM_TRMNTN_CD', 'FAC_NAME', 'ZIP_CD','YEAR','PRVDR_NUM']]
        
        # Merging the dataset with 2016 Active hospitals
        merged_data_year = pd.merge(termination_active_2016_s, short_term_hospital_year_s, on='PRVDR_NUM', how='outer', indicator=True)
        
        # Filtering terminated hospitals
        terminated_hospitals_year = merged_data_year[(merged_data_year['_merge'] == 'left_only') | ((merged_data_year['PGM_TRMNTN_CD_y'] != 0) & (merged_data_year['_merge'] == 'both' ))]
        
        # Store the results in the list
        terminated_hospitals_list.append({
            'year': year,
            'terminated_hospitals': terminated_hospitals_year
        })
        
    return terminated_hospitals_list

# Define the years and the mapping of short-term hospitals
years = [2017, 2018, 2019]

short_term_hospitals_mapping = {
    2017: short_term_hospitals_2017,
    2018: short_term_hospitals_2018,
    2019: short_term_hospitals_2019,
}

# Call the function
terminated_hospitals_result = terminated_hospitals(years, short_term_hospitals_mapping)

# Print the results
for entry in terminated_hospitals_result:
    print(f"Terminated hospitals for {entry['year']}:\n", entry['terminated_hospitals'])


```


```{python}
all_terminated_hospitals = pd.concat([entry['terminated_hospitals'] for entry in terminated_hospitals_result], ignore_index=True)
all_terminated_hospitals
```

```{python}
#Group by FAC to check independent hospital closures
test = all_terminated_hospitals.groupby('PRVDR_NUM').count()
print("Total number of terminated hospitals is",len(test))
```



2. 

```{python}
all_terminated_hospitals_1 = all_terminated_hospitals.sort_values(by='FAC_NAME_x', ascending=True)
all_terminated_hospitals_2 = all_terminated_hospitals_1[['FAC_NAME_x','YEAR_y']]
first_10_rows = all_terminated_hospitals_2.head(10)
print("First 10 hospital name with year of suspected closure is:",first_10_rows)


```



3. 


```{python}
all_terminated_hospitals_3 = all_terminated_hospitals_1.sort_values(by='YEAR_y', ascending=True)
all_terminated_hospitals_4 = all_terminated_hospitals_1[['FAC_NAME_x','YEAR_y','ZIP_CD_x']]
all_terminated_hospitals_4

#Group by data using ZIP_CD_x
all_terminated_hospitals_5 = all_terminated_hospitals_4.groupby(['ZIP_CD_x','YEAR_y']).count()
all_terminated_hospitals_5

all_terminated_hospitals_5['FAC_NAME_x_diff'] = all_terminated_hospitals_5.groupby('ZIP_CD_x')['FAC_NAME_x'].diff()
all_terminated_hospitals_5

```

```{python}

#Find ZIP codes where the number of Diff value is greater than 0
non_decreasing_zip = all_terminated_hospitals_5[all_terminated_hospitals_5['FAC_NAME_x_diff'] > 0 &all_terminated_hospitals_5['FAC_NAME_x_diff'].notna()]
non_decreasing_zip

```


    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 

1. 
    a.
    b. 
2. 

## Calculate zip code’s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 


3. 




